{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os, sys, imp\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "import string\n",
    "import datetime\n",
    "import imp\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Network Analysis\n",
    "import igraph\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "# Clustering\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/hopeemac/Documents/Code/GIT/DSI_Religion/') # Change to Top Level GIT Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hopeemac/Documents/Code/GIT/DSI_Religion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('./prototype_python') # Add location of python prototype to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('./protest_temporalAnalysis/') # Add location of python prototype to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import temporal_methods as tm\n",
    "import semanticDensity as sd\n",
    "import syntacticParsing as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Set up Parameters for Analysis --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group = 'DorothyDay'\n",
    "plotstart = '1933-01-01'\n",
    "plotend = '1981-01-01'\n",
    "plotfilename = 'DorothyDay_temporal.pdf'\n",
    "saveplot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = 'WBC'\n",
    "plotstart = '2007-01-01'\n",
    "plotend = '2016-01-01'\n",
    "plotfilename = 'WBC_temporal.pdf'\n",
    "saveplot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "group = 'MLK'\n",
    "plotstart = '1954-01-01'\n",
    "plotend = '1969-01-01'\n",
    "plotfilename = 'MLK_temporal.pdf'\n",
    "saveplot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "group = 'Ghandi'\n",
    "plotstart = '1915-01-01'\n",
    "plotend = '1949-01-01'\n",
    "plotfilename = 'Ghandi_temporal.pdf'\n",
    "saveplot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Sample of News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articleLoc = './protest_temporalAnalysis/generic_text/NYT_GerberSample/news_documents.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = tm.parse_xml(articleLoc, 'doc', ['id','t','d','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns = ['id','title','date','content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize and Clean News Articles\n",
    "newsTokenLists = {data.loc[rowID,'id']: tokenizer.tokenize(data.loc[rowID,'content']) for rowID in range(0,len(data))}\n",
    "newsTokenLists = {data.loc[rowID,'id']: tm.clean_text(newsTokenLists[data.loc[rowID,'id']]) for rowID in range(0,len(data))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Metadata File for Analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if group == 'DorothyDay':\n",
    "    dataloc = './protest_temporalAnalysis/data_activists/DorothyDay/raw/'\n",
    "    fileData = tm.getDorothyDaymetadata(dataloc)\n",
    "    print(fileData.date_clean.min(), fileData.date_clean.max())\n",
    "    # 1933-05-01 00:00:00 1980-10-01 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-05-27 00:00:00 2015-09-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "if group == 'WBC':\n",
    "    dataloc = './data_dsicap/WBC/raw/'\n",
    "    fileData = tm.getWBCmetadata(dataloc)\n",
    "    print(fileData.date_clean.min(), fileData.date_clean.max())\n",
    "    # 2007-05-27 00:00:00 2015-09-20 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if group == 'MLK':\n",
    "    dataloc = './protest_temporalAnalysis/data_activists/MLK/raw/'\n",
    "    fileData = tm.getSimplemetadata(dataloc)\n",
    "    print(fileData.date_clean.min(), fileData.date_clean.max())\n",
    "    # 1954-02-28 00:00:00 1968-03-31 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if group == 'Ghandi':\n",
    "    dataloc = './protest_temporalAnalysis/data_activists/Ghandi/raw/'\n",
    "    fileData = tm.getSimplemetadata(dataloc)\n",
    "    print(fileData.date_clean.min(), fileData.date_clean.max())\n",
    "    # 1915-04-21 00:00:00 1948-01-12 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize and clean all files in the metadata dataframe, returns a dict\n",
    "tokenLists = {file: tm.tokenize34(dataloc,file) for file in fileData.fileName}\n",
    "tokenLists = {file: tm.clean_text(tokenLists[file]) for file in fileData.fileName}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Removes files shorter than 100 words, not required\n",
    "shortfiles = []\n",
    "for i in range(len(fileData)):\n",
    "    if len(set(tokenLists[fileData.loc[i,'fileName']])) < 100:\n",
    "        # print('problem'+file)\n",
    "        shortfiles.append(i)\n",
    "print(shortfiles)\n",
    "fileData.drop(shortfiles, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only reading in Civil Rights Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = pd.read_excel('./protest_temporalAnalysis/CivilRightsMovement_Dates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = dates[dates.Type == 'Death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Level - Word Count Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get signal relating to how many words in each file. More of a check to understand major\n",
    "# differences between files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = [tm.count_words(tokenLists[file]) for file in fileData.fileName]\n",
    "fileData['wordcount'] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of times the word 'protest is used -- words 'protest' and 'god' are arbitrary\n",
    "protest = [tm.count_specific_words(tokenLists[file], 'protest') for file in fileData.fileName]\n",
    "fileData['protest_word'] = protest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "god = [tm.count_specific_words(tokenLists[file], 'god') for file in fileData.fileName]\n",
    "fileData['god'] = god"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Level - Semantic Density Signal w/ News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates to context vector semantic density algorithm for document level analysis: \n",
    "- create DSM from external source (i.e. set of news articles) instead of bin being analyzed\n",
    "- context vectors are made occurrence of target word in single document with distribution from generic DSM\n",
    "- updated algo to not make/store context vectors unless in target word list\n",
    "- had to account for words in the document, but not in the DSM (smoothing) * not complete, now returns all 0's\n",
    "- updated algo to return # of times target words shows up in the document, to help check for bias in small # of occurences of search word in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get word coCo for News Articles/Generic Text Dataset\n",
    "# CoCo, TF, docTF = sd.coOccurence(newsTokenLists,k=2)\n",
    "#Get DSM for News Articles\n",
    "# DSM=sd.DSM(CoCo,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get word coCo from all Documents in current group's textset\n",
    "# Need token list in dict with filenames as keys\n",
    "CoCo, TF, docTF = sd.coOccurence(tokenLists,k=2)\n",
    "#Get DSM for News Articles\n",
    "DSM=sd.DSM(CoCo,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WestboroBaptist_Sermon_20070527.pdf.txt\n",
      "WestboroBaptist_Sermon_20070624.pdf.txt\n",
      "WestboroBaptist_Sermon_20070701.pdf.txt\n",
      "WestboroBaptist_Sermon_20070708.pdf.txt\n",
      "WestboroBaptist_Sermon_20070715.pdf.txt\n",
      "WestboroBaptist_Sermon_20070722.pdf.txt\n",
      "WestboroBaptist_Sermon_20070729.pdf.txt\n",
      "WestboroBaptist_Sermon_20070805.pdf.txt\n",
      "WestboroBaptist_Sermon_20070812.pdf.txt\n",
      "WestboroBaptist_Sermon_20070819.pdf.txt\n",
      "WestboroBaptist_Sermon_20070826.pdf.txt\n",
      "WestboroBaptist_Sermon_20070902.pdf.txt\n",
      "WestboroBaptist_Sermon_20070909.pdf.txt\n",
      "WestboroBaptist_Sermon_20070916.pdf.txt\n",
      "WestboroBaptist_Sermon_20070923.pdf.txt\n",
      "WestboroBaptist_Sermon_20070930.pdf.txt\n",
      "WestboroBaptist_Sermon_20071007.pdf.txt\n",
      "WestboroBaptist_Sermon_20071014.pdf.txt\n",
      "WestboroBaptist_Sermon_20071021.pdf.txt\n",
      "WestboroBaptist_Sermon_20071104.pdf.txt\n",
      "WestboroBaptist_Sermon_20071111.pdf.txt\n",
      "WestboroBaptist_Sermon_20071118.pdf.txt\n",
      "WestboroBaptist_Sermon_20071125.pdf.txt\n",
      "WestboroBaptist_Sermon_20071202.pdf.txt\n",
      "WestboroBaptist_Sermon_20071209.pdf.txt\n",
      "WestboroBaptist_Sermon_20071216.pdf.txt\n",
      "WestboroBaptist_Sermon_20071223.pdf.txt\n",
      "WestboroBaptist_Sermon_20071230.pdf.txt\n",
      "WestboroBaptist_Sermon_20080106.pdf.txt\n",
      "WestboroBaptist_Sermon_20080113.pdf.txt\n",
      "WestboroBaptist_Sermon_20080120.pdf.txt\n",
      "WestboroBaptist_Sermon_20080127.pdf.txt\n",
      "WestboroBaptist_Sermon_20080210.pdf.txt\n",
      "WestboroBaptist_Sermon_20080217.pdf.txt\n",
      "WestboroBaptist_Sermon_20080224.pdf.txt\n",
      "WestboroBaptist_Sermon_20080302.pdf.txt\n",
      "WestboroBaptist_Sermon_20080309.pdf.txt\n",
      "WestboroBaptist_Sermon_20080316.pdf.txt\n",
      "WestboroBaptist_Sermon_20080323.pdf.txt\n",
      "WestboroBaptist_Sermon_20080330.pdf.txt\n",
      "WestboroBaptist_Sermon_20080406.pdf.txt\n",
      "WestboroBaptist_Sermon_20080413.pdf.txt\n",
      "WestboroBaptist_Sermon_20080420.pdf.txt\n",
      "WestboroBaptist_Sermon_20080427.pdf.txt\n",
      "WestboroBaptist_Sermon_20080504.pdf.txt\n",
      "WestboroBaptist_Sermon_20080511.pdf.txt\n",
      "WestboroBaptist_Sermon_20080518.pdf.txt\n",
      "WestboroBaptist_Sermon_20080525.pdf.txt\n",
      "WestboroBaptist_Sermon_20080601.pdf.txt\n",
      "WestboroBaptist_Sermon_20080608.pdf.txt\n",
      "WestboroBaptist_Sermon_20080615.pdf.txt\n",
      "WestboroBaptist_Sermon_20080622.pdf.txt\n",
      "WestboroBaptist_Sermon_20080629.pdf.txt\n",
      "WestboroBaptist_Sermon_20080706.pdf.txt\n",
      "WestboroBaptist_Sermon_20080713.pdf.txt\n",
      "WestboroBaptist_Sermon_20080720.pdf.txt\n",
      "WestboroBaptist_Sermon_20080727.pdf.txt\n",
      "WestboroBaptist_Sermon_20080803.pdf.txt\n",
      "WestboroBaptist_Sermon_20080810.pdf.txt\n",
      "WestboroBaptist_Sermon_20080817.pdf.txt\n",
      "WestboroBaptist_Sermon_20080824.pdf.txt\n",
      "WestboroBaptist_Sermon_20080831.pdf.txt\n",
      "WestboroBaptist_Sermon_20080907.pdf.txt\n",
      "WestboroBaptist_Sermon_20080914.pdf.txt\n",
      "WestboroBaptist_Sermon_20080921.pdf.txt\n",
      "WestboroBaptist_Sermon_20080928.pdf.txt\n",
      "WestboroBaptist_Sermon_20081005.pdf.txt\n",
      "WestboroBaptist_Sermon_20081012.pdf.txt\n",
      "WestboroBaptist_Sermon_20081019.pdf.txt\n",
      "WestboroBaptist_Sermon_20081026.pdf.txt\n",
      "WestboroBaptist_Sermon_20081102.pdf.txt\n",
      "WestboroBaptist_Sermon_20081109.pdf.txt\n",
      "WestboroBaptist_Sermon_20081116.pdf.txt\n",
      "WestboroBaptist_Sermon_20081123.pdf.txt\n",
      "WestboroBaptist_Sermon_20081130.pdf.txt\n",
      "WestboroBaptist_Sermon_20081207.pdf.txt\n",
      "WestboroBaptist_Sermon_20081214.pdf.txt\n",
      "WestboroBaptist_Sermon_20081221.pdf.txt\n",
      "WestboroBaptist_Sermon_20081228.pdf.txt\n",
      "WestboroBaptist_Sermon_20090104.pdf.txt\n",
      "WestboroBaptist_Sermon_20090111.pdf.txt\n",
      "WestboroBaptist_Sermon_20090125.pdf.txt\n",
      "WestboroBaptist_Sermon_20090201.pdf.txt\n",
      "WestboroBaptist_Sermon_20090208.pdf.txt\n",
      "WestboroBaptist_Sermon_20090215.pdf.txt\n",
      "WestboroBaptist_Sermon_20090222.pdf.txt\n",
      "WestboroBaptist_Sermon_20090301.pdf.txt\n",
      "WestboroBaptist_Sermon_20090308.pdf.txt\n",
      "WestboroBaptist_Sermon_20090315.pdf.txt\n",
      "WestboroBaptist_Sermon_20090419.pdf.txt\n",
      "WestboroBaptist_Sermon_20090426.pdf.txt\n",
      "WestboroBaptist_Sermon_20090503.pdf.txt\n",
      "WestboroBaptist_Sermon_20090510.pdf.txt\n",
      "WestboroBaptist_Sermon_20090517.pdf.txt\n",
      "WestboroBaptist_Sermon_20090524.pdf.txt\n",
      "WestboroBaptist_Sermon_20090531.pdf.txt\n",
      "WestboroBaptist_Sermon_20090607.pdf.txt\n",
      "WestboroBaptist_Sermon_20090614.pdf.txt\n",
      "WestboroBaptist_Sermon_20090621.pdf.txt\n",
      "WestboroBaptist_Sermon_20090628.pdf.txt\n",
      "WestboroBaptist_Sermon_20090705.pdf.txt\n",
      "WestboroBaptist_Sermon_20090712.pdf.txt\n",
      "WestboroBaptist_Sermon_20090719.pdf.txt\n",
      "WestboroBaptist_Sermon_20090726.pdf.txt\n",
      "WestboroBaptist_Sermon_20090802.pdf.txt\n",
      "WestboroBaptist_Sermon_20090809.pdf.txt\n",
      "WestboroBaptist_Sermon_20090816.pdf.txt\n",
      "WestboroBaptist_Sermon_20090823.pdf.txt\n",
      "WestboroBaptist_Sermon_20090906.pdf.txt\n",
      "WestboroBaptist_Sermon_20090913.pdf.txt\n",
      "WestboroBaptist_Sermon_20090920.pdf.txt\n",
      "WestboroBaptist_Sermon_20090927.pdf.txt\n",
      "WestboroBaptist_Sermon_20091004.pdf.txt\n",
      "WestboroBaptist_Sermon_20091011.pdf.txt\n",
      "WestboroBaptist_Sermon_20091018.pdf.txt\n",
      "WestboroBaptist_Sermon_20091025.pdf.txt\n",
      "WestboroBaptist_Sermon_20091101.pdf.txt\n",
      "WestboroBaptist_Sermon_20091108.pdf.txt\n",
      "WestboroBaptist_Sermon_20091115.pdf.txt\n",
      "WestboroBaptist_Sermon_20091122.pdf.txt\n",
      "WestboroBaptist_Sermon_20091129.pdf.txt\n",
      "WestboroBaptist_Sermon_20091206.pdf.txt\n",
      "WestboroBaptist_Sermon_20091213.pdf.txt\n",
      "WestboroBaptist_Sermon_20091220.pdf.txt\n",
      "WestboroBaptist_Sermon_20091227.pdf.txt\n",
      "WestboroBaptist_Sermon_20100103.pdf.txt\n",
      "WestboroBaptist_Sermon_20100110.pdf.txt\n",
      "WestboroBaptist_Sermon_20100117.pdf.txt\n",
      "WestboroBaptist_Sermon_20100124.pdf.txt\n",
      "WestboroBaptist_Sermon_20100131.pdf.txt\n",
      "WestboroBaptist_Sermon_20100207.pdf.txt\n",
      "WestboroBaptist_Sermon_20100214.pdf.txt\n",
      "WestboroBaptist_Sermon_20100221.pdf.txt\n",
      "WestboroBaptist_Sermon_20100228.pdf.txt\n",
      "WestboroBaptist_Sermon_20100307.pdf.txt\n",
      "WestboroBaptist_Sermon_20100314.pdf.txt\n",
      "WestboroBaptist_Sermon_20100321.pdf.txt\n",
      "WestboroBaptist_Sermon_20100328.pdf.txt\n",
      "WestboroBaptist_Sermon_20100404.pdf.txt\n",
      "WestboroBaptist_Sermon_20100411.pdf.txt\n",
      "WestboroBaptist_Sermon_20100418.pdf.txt\n",
      "WestboroBaptist_Sermon_20100421.pdf.txt\n",
      "WestboroBaptist_Sermon_20100425.pdf.txt\n",
      "WestboroBaptist_Sermon_20100502.pdf.txt\n",
      "WestboroBaptist_Sermon_20100509.pdf.txt\n",
      "WestboroBaptist_Sermon_20100516.pdf.txt\n",
      "WestboroBaptist_Sermon_20100523.pdf.txt\n",
      "WestboroBaptist_Sermon_20100530.pdf.txt\n",
      "WestboroBaptist_Sermon_20100606.pdf.txt\n",
      "WestboroBaptist_Sermon_20100613.pdf.txt\n",
      "WestboroBaptist_Sermon_20100620.pdf.txt\n",
      "WestboroBaptist_Sermon_20100627.pdf.txt\n",
      "WestboroBaptist_Sermon_20100704.pdf.txt\n",
      "WestboroBaptist_Sermon_20100711.pdf.txt\n",
      "WestboroBaptist_Sermon_20100718.pdf.txt\n",
      "WestboroBaptist_Sermon_20100725.pdf.txt\n",
      "WestboroBaptist_Sermon_20100801.pdf.txt\n",
      "WestboroBaptist_Sermon_20100808.pdf.txt\n",
      "WestboroBaptist_Sermon_20100815.pdf.txt\n",
      "WestboroBaptist_Sermon_20100822.pdf.txt\n",
      "WestboroBaptist_Sermon_20100829.pdf.txt\n",
      "WestboroBaptist_Sermon_20100905.pdf.txt\n",
      "WestboroBaptist_Sermon_20100912.pdf.txt\n",
      "WestboroBaptist_Sermon_20100919.pdf.txt\n",
      "WestboroBaptist_Sermon_20100926.pdf.txt\n",
      "WestboroBaptist_Sermon_20101001.pdf.txt\n",
      "WestboroBaptist_Sermon_20101010.pdf.txt\n",
      "WestboroBaptist_Sermon_20101017.pdf.txt\n",
      "WestboroBaptist_Sermon_20101024.pdf.txt\n",
      "WestboroBaptist_Sermon_20101031.pdf.txt\n",
      "WestboroBaptist_Sermon_20101107.pdf.txt\n",
      "WestboroBaptist_Sermon_20101114.pdf.txt\n",
      "WestboroBaptist_Sermon_20101121.pdf.txt\n",
      "WestboroBaptist_Sermon_20101128.pdf.txt\n",
      "WestboroBaptist_Sermon_20101205.pdf.txt\n",
      "WestboroBaptist_Sermon_20101212.pdf.txt\n",
      "WestboroBaptist_Sermon_20101219.pdf.txt\n",
      "WestboroBaptist_Sermon_20101226.pdf.txt\n",
      "WestboroBaptist_Sermon_20110102.pdf.txt\n",
      "WestboroBaptist_Sermon_20110109.pdf.txt\n",
      "WestboroBaptist_Sermon_20110116.pdf.txt\n",
      "WestboroBaptist_Sermon_20110123.pdf.txt\n",
      "WestboroBaptist_Sermon_20110130.pdf.txt\n",
      "WestboroBaptist_Sermon_20110206.pdf.txt\n",
      "WestboroBaptist_Sermon_20110213.pdf.txt\n",
      "WestboroBaptist_Sermon_20110220.pdf.txt\n",
      "WestboroBaptist_Sermon_20110227.pdf.txt\n",
      "WestboroBaptist_Sermon_20110306.pdf.txt\n",
      "WestboroBaptist_Sermon_20110313.pdf.txt\n",
      "WestboroBaptist_Sermon_20110320.pdf.txt\n",
      "WestboroBaptist_Sermon_20110327.pdf.txt\n",
      "WestboroBaptist_Sermon_20110403.pdf.txt\n",
      "WestboroBaptist_Sermon_20110410.pdf.txt\n",
      "WestboroBaptist_Sermon_20110417.pdf.txt\n",
      "WestboroBaptist_Sermon_20110424.pdf.txt\n",
      "WestboroBaptist_Sermon_20110501.pdf.txt\n",
      "WestboroBaptist_Sermon_20110508.pdf.txt\n",
      "WestboroBaptist_Sermon_20110515.pdf.txt\n",
      "WestboroBaptist_Sermon_20110522.pdf.txt\n",
      "WestboroBaptist_Sermon_20110529.pdf.txt\n",
      "WestboroBaptist_Sermon_20110605.pdf.txt\n",
      "WestboroBaptist_Sermon_20110612.pdf.txt\n",
      "WestboroBaptist_Sermon_20110619.pdf.txt\n",
      "WestboroBaptist_Sermon_20110626.pdf.txt\n",
      "WestboroBaptist_Sermon_20110703.pdf.txt\n",
      "WestboroBaptist_Sermon_20110710.pdf.txt\n",
      "WestboroBaptist_Sermon_20110717.pdf.txt\n",
      "WestboroBaptist_Sermon_20110724.pdf.txt\n",
      "WestboroBaptist_Sermon_20110731.pdf.txt\n",
      "WestboroBaptist_Sermon_20110807.pdf.txt\n",
      "WestboroBaptist_Sermon_20110814.pdf.txt\n",
      "WestboroBaptist_Sermon_20110821.pdf.txt\n",
      "WestboroBaptist_Sermon_20110828.pdf.txt\n",
      "WestboroBaptist_Sermon_20110904.pdf.txt\n",
      "WestboroBaptist_Sermon_20110911.pdf.txt\n",
      "WestboroBaptist_Sermon_20110918.pdf.txt\n",
      "WestboroBaptist_Sermon_20110925.pdf.txt\n",
      "WestboroBaptist_Sermon_20111002.pdf.txt\n",
      "WestboroBaptist_Sermon_20111009.pdf.txt\n",
      "WestboroBaptist_Sermon_20111016.pdf.txt\n",
      "WestboroBaptist_Sermon_20111023.pdf.txt\n",
      "WestboroBaptist_Sermon_20111030.pdf.txt\n",
      "WestboroBaptist_Sermon_20111106.pdf.txt\n",
      "WestboroBaptist_Sermon_20111113.pdf.txt\n",
      "WestboroBaptist_Sermon_20111120.pdf.txt\n",
      "WestboroBaptist_Sermon_20111127.pdf.txt\n",
      "WestboroBaptist_Sermon_20111204.pdf.txt\n",
      "WestboroBaptist_Sermon_20111211.pdf.txt\n",
      "WestboroBaptist_Sermon_20111218.pdf.txt\n",
      "WestboroBaptist_Sermon_20111225.pdf.txt\n",
      "WestboroBaptist_Sermon_20120101.pdf.txt\n",
      "WestboroBaptist_Sermon_20120108.pdf.txt\n",
      "WestboroBaptist_Sermon_20120115.pdf.txt\n",
      "WestboroBaptist_Sermon_20120122.pdf.txt\n",
      "WestboroBaptist_Sermon_20120129.pdf.txt\n",
      "WestboroBaptist_Sermon_20120205.pdf.txt\n",
      "WestboroBaptist_Sermon_20120212.pdf.txt\n",
      "WestboroBaptist_Sermon_20120219.pdf.txt\n",
      "WestboroBaptist_Sermon_20120226.pdf.txt\n",
      "WestboroBaptist_Sermon_20120304.pdf.txt\n",
      "WestboroBaptist_Sermon_20120311.pdf.txt\n",
      "WestboroBaptist_Sermon_20120318.pdf.txt\n",
      "WestboroBaptist_Sermon_20120325.pdf.txt\n",
      "WestboroBaptist_Sermon_20120401.pdf.txt\n",
      "WestboroBaptist_Sermon_20120408.pdf.txt\n",
      "WestboroBaptist_Sermon_20120415.pdf.txt\n",
      "WestboroBaptist_Sermon_20120422.pdf.txt\n",
      "WestboroBaptist_Sermon_20120429.pdf.txt\n",
      "WestboroBaptist_Sermon_20120506.pdf.txt\n",
      "WestboroBaptist_Sermon_20120513.pdf.txt\n",
      "WestboroBaptist_Sermon_20120520.pdf.txt\n",
      "WestboroBaptist_Sermon_20120527.pdf.txt\n",
      "WestboroBaptist_Sermon_20120603.pdf.txt\n",
      "WestboroBaptist_Sermon_20120610.pdf.txt\n",
      "WestboroBaptist_Sermon_20120617.pdf.txt\n",
      "WestboroBaptist_Sermon_20120624.pdf.txt\n",
      "WestboroBaptist_Sermon_20120701.pdf.txt\n",
      "WestboroBaptist_Sermon_20120708.pdf.txt\n",
      "WestboroBaptist_Sermon_20120715.pdf.txt\n",
      "WestboroBaptist_Sermon_20120722.pdf.txt\n",
      "WestboroBaptist_Sermon_20120729.pdf.txt\n",
      "WestboroBaptist_Sermon_20120805.pdf.txt\n",
      "WestboroBaptist_Sermon_20120812.pdf.txt\n",
      "WestboroBaptist_Sermon_20120819.pdf.txt\n",
      "WestboroBaptist_Sermon_20120826.pdf.txt\n",
      "WestboroBaptist_Sermon_20120902.pdf.txt\n",
      "WestboroBaptist_Sermon_20120909.pdf.txt\n",
      "WestboroBaptist_Sermon_20120916.pdf.txt\n",
      "WestboroBaptist_Sermon_20120923.pdf.txt\n",
      "WestboroBaptist_Sermon_20120930.pdf.txt\n",
      "WestboroBaptist_Sermon_20121007.pdf.txt\n",
      "WestboroBaptist_Sermon_20121014.pdf.txt\n",
      "WestboroBaptist_Sermon_20121021.pdf.txt\n",
      "WestboroBaptist_Sermon_20121028.pdf.txt\n",
      "WestboroBaptist_Sermon_20121104.pdf.txt\n",
      "WestboroBaptist_Sermon_20121111.pdf.txt\n",
      "WestboroBaptist_Sermon_20121118.pdf.txt\n",
      "WestboroBaptist_Sermon_20121125.pdf.txt\n",
      "WestboroBaptist_Sermon_20121202.pdf.txt\n",
      "WestboroBaptist_Sermon_20121209.pdf.txt\n",
      "WestboroBaptist_Sermon_20121216.pdf.txt\n",
      "WestboroBaptist_Sermon_20121223.pdf.txt\n",
      "WestboroBaptist_Sermon_20121230.pdf.txt\n",
      "WestboroBaptist_Sermon_20130106.pdf.txt\n",
      "WestboroBaptist_Sermon_20130113.pdf.txt\n",
      "WestboroBaptist_Sermon_20130120.pdf.txt\n",
      "WestboroBaptist_Sermon_20130127.pdf.txt\n",
      "WestboroBaptist_Sermon_20130203.pdf.txt\n",
      "WestboroBaptist_Sermon_20130210.pdf.txt\n",
      "WestboroBaptist_Sermon_20130217.pdf.txt\n",
      "WestboroBaptist_Sermon_20130224.pdf.txt\n",
      "WestboroBaptist_Sermon_20130303.pdf.txt\n",
      "WestboroBaptist_Sermon_20130310.pdf.txt\n",
      "WestboroBaptist_Sermon_20130317.pdf.txt\n",
      "WestboroBaptist_Sermon_20130324.pdf.txt\n",
      "WestboroBaptist_Sermon_20130331.pdf.txt\n",
      "WestboroBaptist_Sermon_20130407.pdf.txt\n",
      "WestboroBaptist_Sermon_20130414.pdf.txt\n",
      "WestboroBaptist_Sermon_20130421.pdf.txt\n",
      "WestboroBaptist_Sermon_20130428.pdf.txt\n",
      "WestboroBaptist_Sermon_20130505.pdf.txt\n",
      "WestboroBaptist_Sermon_20130512.pdf.txt\n",
      "WestboroBaptist_Sermon_20130519.pdf.txt\n",
      "WestboroBaptist_Sermon_20130526.pdf.txt\n",
      "WestboroBaptist_Sermon_20130602.pdf.txt\n",
      "WestboroBaptist_Sermon_20130609.pdf.txt\n",
      "WestboroBaptist_Sermon_20130616.pdf.txt\n",
      "WestboroBaptist_Sermon_20130623.pdf.txt\n",
      "WestboroBaptist_Sermon_20130630.pdf.txt\n",
      "WestboroBaptist_Sermon_20130707.pdf.txt\n",
      "WestboroBaptist_Sermon_20130714.pdf.txt\n",
      "WestboroBaptist_Sermon_20130721.pdf.txt\n",
      "WestboroBaptist_Sermon_20130728.pdf.txt\n",
      "WestboroBaptist_Sermon_20130804.pdf.txt\n",
      "WestboroBaptist_Sermon_20130818.pdf.txt\n",
      "WestboroBaptist_Sermon_20130825.pdf.txt\n",
      "WestboroBaptist_Sermon_20130901.pdf.txt\n",
      "WestboroBaptist_Sermon_20131006.pdf.txt\n",
      "WestboroBaptist_Sermon_20131013.pdf.txt\n",
      "WestboroBaptist_Sermon_20131020.pdf.txt\n",
      "WestboroBaptist_Sermon_20131027.pdf.txt\n",
      "WestboroBaptist_Sermon_20131103.pdf.txt\n",
      "WestboroBaptist_Sermon_20131110.pdf.txt\n",
      "WestboroBaptist_Sermon_20131117.pdf.txt\n",
      "WestboroBaptist_Sermon_20131124.pdf.txt\n",
      "WestboroBaptist_Sermon_20131201.pdf.txt\n",
      "WestboroBaptist_Sermon_20131208.pdf.txt\n",
      "WestboroBaptist_Sermon_20131215.pdf.txt\n",
      "WestboroBaptist_Sermon_20131222.pdf.txt\n",
      "WestboroBaptist_Sermon_20131229.pdf.txt\n",
      "WestboroBaptist_Sermon_20140105.pdf.txt\n",
      "WestboroBaptist_Sermon_20140112.pdf.txt\n",
      "WestboroBaptist_Sermon_20140119.pdf.txt\n",
      "WestboroBaptist_Sermon_20140126.pdf.txt\n",
      "WestboroBaptist_Sermon_20140202.pdf.txt\n",
      "WestboroBaptist_Sermon_20140209.pdf.txt\n",
      "WestboroBaptist_Sermon_20140216.pdf.txt\n",
      "WestboroBaptist_Sermon_20140223.pdf.txt\n",
      "WestboroBaptist_Sermon_20140302.pdf.txt\n",
      "WestboroBaptist_Sermon_20140309.pdf.txt\n",
      "WestboroBaptist_Sermon_20140316.pdf.txt\n",
      "WestboroBaptist_Sermon_20140323.pdf.txt\n",
      "WestboroBaptist_Sermon_20140330.pdf.txt\n",
      "WestboroBaptist_Sermon_20140406.pdf.txt\n",
      "WestboroBaptist_Sermon_20140413.pdf.txt\n",
      "WestboroBaptist_Sermon_20140420.pdf.txt\n",
      "WestboroBaptist_Sermon_20140427.pdf.txt\n",
      "WestboroBaptist_Sermon_20140504.pdf.txt\n",
      "WestboroBaptist_Sermon_20140511.pdf.txt\n",
      "WestboroBaptist_Sermon_20140518.pdf.txt\n",
      "WestboroBaptist_Sermon_20140525.pdf.txt\n",
      "WestboroBaptist_Sermon_20140601.pdf.txt\n",
      "WestboroBaptist_Sermon_20140608.pdf.txt\n",
      "WestboroBaptist_Sermon_20140615.pdf.txt\n",
      "WestboroBaptist_Sermon_20140622.pdf.txt\n",
      "WestboroBaptist_Sermon_20140629.pdf.txt\n",
      "WestboroBaptist_Sermon_20140706.pdf.txt\n",
      "WestboroBaptist_Sermon_20140713.pdf.txt\n",
      "WestboroBaptist_Sermon_20140720.pdf.txt\n",
      "WestboroBaptist_Sermon_20140727.pdf.txt\n",
      "WestboroBaptist_Sermon_20140803.pdf.txt\n",
      "WestboroBaptist_Sermon_20140810.pdf.txt\n",
      "WestboroBaptist_Sermon_20140817.pdf.txt\n",
      "WestboroBaptist_Sermon_20140824.pdf.txt\n",
      "WestboroBaptist_Sermon_20140831.pdf.txt\n",
      "WestboroBaptist_Sermon_20140907.pdf.txt\n",
      "WestboroBaptist_Sermon_20140914.pdf.txt\n",
      "WestboroBaptist_Sermon_20140921.pdf.txt\n",
      "WestboroBaptist_Sermon_20140928.pdf.txt\n",
      "WestboroBaptist_Sermon_20141005.pdf.txt\n",
      "WestboroBaptist_Sermon_20141012.pdf.txt\n",
      "WestboroBaptist_Sermon_20141019.pdf.txt\n",
      "WestboroBaptist_Sermon_20141026.pdf.txt\n",
      "WestboroBaptist_Sermon_20141102.pdf.txt\n",
      "WestboroBaptist_Sermon_20141109.pdf.txt\n",
      "WestboroBaptist_Sermon_20141116.pdf.txt\n",
      "WestboroBaptist_Sermon_20141123.pdf.txt\n",
      "WestboroBaptist_Sermon_20141130.pdf.txt\n",
      "WestboroBaptist_Sermon_20141207.pdf.txt\n",
      "WestboroBaptist_Sermon_20141214.pdf.txt\n",
      "WestboroBaptist_Sermon_20141221.pdf.txt\n",
      "WestboroBaptist_Sermon_20141228.pdf.txt\n",
      "WestboroBaptist_Sermon_20150104.pdf.txt\n",
      "WestboroBaptist_Sermon_20150111.pdf.txt\n",
      "WestboroBaptist_Sermon_20150118.pdf.txt\n",
      "WestboroBaptist_Sermon_20150125.pdf.txt\n",
      "WestboroBaptist_Sermon_20150201.pdf.txt\n",
      "WestboroBaptist_Sermon_20150208.pdf.txt\n",
      "WestboroBaptist_Sermon_20150215.pdf.txt\n",
      "WestboroBaptist_Sermon_20150222.pdf.txt\n",
      "WestboroBaptist_Sermon_20150301.pdf.txt\n",
      "WestboroBaptist_Sermon_20150308.pdf.txt\n",
      "WestboroBaptist_Sermon_20150315.pdf.txt\n",
      "WestboroBaptist_Sermon_20150322.pdf.txt\n",
      "WestboroBaptist_Sermon_20150329.pdf.txt\n",
      "WestboroBaptist_Sermon_20150405.pdf.txt\n",
      "WestboroBaptist_Sermon_20150412.pdf.txt\n",
      "WestboroBaptist_Sermon_20150419.pdf.txt\n",
      "WestboroBaptist_Sermon_20150426.pdf.txt\n",
      "WestboroBaptist_Sermon_20150503.pdf.txt\n",
      "WestboroBaptist_Sermon_20150510.pdf.txt\n",
      "WestboroBaptist_Sermon_20150524.pdf.txt\n",
      "WestboroBaptist_Sermon_20150531.pdf.txt\n",
      "WestboroBaptist_Sermon_20150607.pdf.txt\n",
      "WestboroBaptist_Sermon_20150614.pdf.txt\n",
      "WestboroBaptist_Sermon_20150621.pdf.txt\n",
      "WestboroBaptist_Sermon_20150628.pdf.txt\n",
      "WestboroBaptist_Sermon_20150705.pdf.txt\n",
      "WestboroBaptist_Sermon_20150712.pdf.txt\n",
      "WestboroBaptist_Sermon_20150719.pdf.txt\n",
      "WestboroBaptist_Sermon_20150726.pdf.txt\n",
      "WestboroBaptist_Sermon_20150802.pdf.txt\n",
      "WestboroBaptist_Sermon_20150809.pdf.txt\n",
      "WestboroBaptist_Sermon_20150816.pdf.txt\n",
      "WestboroBaptist_Sermon_20150823.pdf.txt\n",
      "WestboroBaptist_Sermon_20150830.pdf.txt\n",
      "WestboroBaptist_Sermon_20150906.pdf.txt\n",
      "WestboroBaptist_Sermon_20150913.pdf.txt\n",
      "WestboroBaptist_Sermon_20150920.pdf.txt\n"
     ]
    }
   ],
   "source": [
    "semanticDensity=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    CVDict=tm.contextVectors(tokenLists[file], DSM, ['the'], 2)\n",
    "    cosineSimilarity=tm.averageCosine(CVDict,simCount=10000)\n",
    "    avgSD=np.mean([x[1] for x in cosineSimilarity])\n",
    "    semanticDensity = semanticDensity+[avgSD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileData['semanticDensity_the'] = semanticDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_dsicap/WBC/raw/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hopeemac/Documents/Code/GIT/DSI_Religion'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dictionary with the list of Top 10 Adj/Adv for each document, will be reused\n",
    "targetwords = {}\n",
    "for file in fileData.fileName:\n",
    "    targetwords[file] = sp.targetWords(tm.getRawText(dataloc,file),wordCount=10,startCount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semanticDensity=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    # targetwords = sp.targetWords(tm.getRawText(dataloc,file),wordCount=10,startCount=0)\n",
    "    CVDict=tm.contextVectors(tokenLists[file], DSM, targetwords[file], 2)\n",
    "    cosineSimilarity=tm.averageCosine(CVDict,simCount=10000)\n",
    "    avgSD=np.mean([x[1] for x in cosineSimilarity])\n",
    "    semanticDensity = semanticDensity+[avgSD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileData['semanticDensity_adjadv'] = semanticDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Level Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates to Sentiment algorithm for document level analysis: \n",
    "- % pos/neg words by document instead of averaged over bin\n",
    "- don't have signal of % pos/neg documents per bin bc not relevant to single-document analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start=datetime.datetime.now()\n",
    "sentiment=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    sent = tm.sentimentLookup(tokenLists[file])\n",
    "    sentiment.append(sent) # Returns %pos, %neg, #pos, #\n",
    "print(datetime.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extracts the %pos from the returned tuple\n",
    "s=[sent[0][0] for sent in sentiment]\n",
    "fileData['sentiment_pos']=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts the %neg from the returned tuple\n",
    "s=[sent[0][1] for sent in sentiment]\n",
    "fileData['sentiment_neg']=s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Level Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates to network algorithm for document level analysis: \n",
    "- Using Top 10 (or less) Adj/Adv from the Single Document for analysis (maybe should switch this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def getNetworkQuant(dsm,targetWords,netAngle):\n",
    "    \n",
    "    #Get list of values in DSM\n",
    "    dsmList=[list(dsm[key].values()) for key in dsm.keys()]\n",
    "    # print(dsmList)\n",
    "    #Calculate distances for each set of values in dsm\n",
    "    cosineNP=ssd.cdist(dsmList,dsmList,metric='cosine')\n",
    "    \n",
    "    adj = cosineNP.copy()\n",
    "    \n",
    "    #Apply thresholds\n",
    "    adj[np.abs(cosineNP) >= math.cos(math.radians(netAngle))] = 0 # Converting 30 degree threshold to radians to a cosine value\n",
    "    \n",
    "    adj[np.abs(cosineNP) < math.cos(math.radians(netAngle))] = 1 # Converting 30 degree threshold to radians to a cosine value\n",
    "    \n",
    "    adjList = pd.DataFrame(adj,columns=dsm.keys(),index=dsm.keys()).values.tolist()\n",
    "    \n",
    "    #Create network graph\n",
    "    net = igraph.Graph.Adjacency(adjList, mode = \"undirected\")\n",
    "    \n",
    "    #Get eigenvector centrality\n",
    "    ev_centrality = igraph.Graph.evcent(net)\n",
    "    \n",
    "    # ** Double Check this Subseting ** #\n",
    "    #Get mean eigenvector centrality for words in target list\n",
    "    meanEVC=np.mean([ev_centrality[i] for i in range(len(dsm.keys())) if list(dsm.keys())[i] in targetWords])\n",
    "    return(meanEVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    #Get word coCo for Single Document\n",
    "    CoCo, TF, docTF = sd.coOccurence({file: tokenLists[file]},k=2)\n",
    "    #Get DSM for Single Document\n",
    "    DSM=sd.DSM(CoCo,100)\n",
    "    result=getNetworkQuant(DSM,targetwords[file],30)\n",
    "    network.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileData['network']=network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Level Subgraph Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning: Function to acquire this metric not accurate/complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def getSubgraphCent(dsm,targetwords,netAngle):\n",
    "    # Get index location of Target Word, will match the vertex in the graph\n",
    "    targetindex = []\n",
    "    for word in targetwords:\n",
    "        targetindex.append(list(dsm.keys()).index(word))\n",
    "    \n",
    "    #Get list of values in DSM\n",
    "    dsmList=[list(dsm[key].values()) for key in dsm.keys()]\n",
    "    # print(dsmList)\n",
    "    #Calculate distances for each set of values in dsm\n",
    "    cosineNP=ssd.cdist(dsmList,dsmList,metric='cosine')\n",
    "    \n",
    "    adj = cosineNP.copy()\n",
    "    \n",
    "    #Apply thresholds\n",
    "    adj[np.abs(cosineNP) >= math.cos(math.radians(netAngle))] = 0 # Converting 30 degree threshold to radians to a cosine value\n",
    "    \n",
    "    adj[np.abs(cosineNP) < math.cos(math.radians(netAngle))] = 1 # Converting 30 degree threshold to radians to a cosine value\n",
    "    \n",
    "    adjList = pd.DataFrame(adj,columns=dsm.keys(),index=dsm.keys()).values.tolist()\n",
    "    \n",
    "    #Create network graph\n",
    "    graph = igraph.Graph.Adjacency(adjList, mode = \"undirected\")\n",
    "    \n",
    "    # Get measure of the centrality of the subgraph containing only the target words\n",
    "    subgraph = igraph.Graph.subgraph(graph, targetindex)\n",
    "    centrality = sum(subgraph.betweenness()) / len(targetindex)\n",
    "\n",
    "    return(centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Level Judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates to Judgements algorithm for document level analysis: \n",
    "- percent of judgements is based on a 1 document, not the average of all documents in bin\n",
    "- only using % judgements, not raw count of number of judgement sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import syntacticParsing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judgements=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    rawText = tm.getRawText(dataloc,file)\n",
    "    percent=sp.judgements(rawText)\n",
    "    judgements.append(percent)\n",
    "    #judgementAvg=list(np.mean(np.array(judgementList),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=[judge[1] for judge in judgements]\n",
    "fileData['judgements']=j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Level Word Usage Calculation from Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to create context vectors\n",
    "def make_coOcVectors_TFdict(tokenList,wordlist,k):\n",
    "    'Returns vectors of words within window for each occurrence of word in wordlist'\n",
    "    \n",
    "    #Define coOccurence dict\n",
    "    cvDict={}\n",
    "\n",
    "    for i in range(len(tokenList)):\n",
    "        targetword=tokenList[i] # Changed window to targetword for more clarity\n",
    "        \n",
    "        if targetword in wordlist:\n",
    "            # print(targetword)\n",
    "            #Adjust window to contain words k in front or k behind\n",
    "            lowerBound=max(0,i-k)\n",
    "            upperBound=min(len(tokenList),i+k)\n",
    "            cvList=tokenList[lowerBound:i]+tokenList[i+1:upperBound+1]\n",
    "    \n",
    "            if targetword not in cvDict.keys():\n",
    "                cvDict[targetword]={}\n",
    "            \n",
    "            #Add context vector to cvDict\n",
    "            cvIndex=len(cvDict[targetword])+1\n",
    "            cvDict[targetword][cvIndex]={}\n",
    "            \n",
    "            for word in cvList:\n",
    "                if word in cvDict[targetword][cvIndex]:\n",
    "                    cvDict[targetword][cvIndex][word] += 1\n",
    "                else:\n",
    "                    cvDict[targetword][cvIndex][word] = 1\n",
    "    \n",
    "    #Return context vector dictionary\n",
    "    return(cvDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordUsage(tokenlist,targetwords,windowSize):\n",
    "    # Make sure 'nt' converted to 'not' in target word list\n",
    "    targetwords = [word for word in targetwords if word != 'nt']\n",
    "    \n",
    "    coOc_TFdict=make_coOcVectors_TFdict(tokenlist, targetwords, windowSize)\n",
    "   \n",
    "    # Distance Threshold for Cluster Cutoff\n",
    "    max_d = 2.0\n",
    "\n",
    "    cluster_count = []\n",
    "    cluster_count_norm = []\n",
    "\n",
    "    for target in targetwords:\n",
    "        # Covert Dict of Co-Occurrances to DTM\n",
    "        coCoDictList = []\n",
    "        for key in coOc_TFdict[target].keys():\n",
    "            coCoDictList.append(coOc_TFdict[target][key])\n",
    "        dv = DictVectorizer(sparse=True)\n",
    "        dtm = dv.fit_transform(coCoDictList)\n",
    "        dist = 1 - cosine_similarity(dtm)\n",
    "        linkage_matrix = ward(dist)\n",
    "        names=list(coOc_TFdict[target].keys())\n",
    "\n",
    "        # Get number of distinct clusters\n",
    "        clusters = fcluster(linkage_matrix, max_d, criterion='distance')\n",
    "\n",
    "        cluster_count.append(max(clusters))\n",
    "        cluster_count_norm.append(max(clusters)/len(names))\n",
    "\n",
    "    return (mean(cluster_count), mean(cluster_count_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start=datetime.datetime.now()\n",
    "usage=[]\n",
    "for file in fileData.fileName:\n",
    "    print(file)\n",
    "    use = getWordUsage(tokenLists[file],targetwords[file],4)\n",
    "    usage.append(use) # Returns %pos, %neg, #pos, #\n",
    "print(datetime.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts the average number of uses/clusters for the set of target words in documents\n",
    "u=[use[0] for use in usage]\n",
    "fileData['uses']=u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts the average number of uses/clusters normalized by number of occurrences\n",
    "u=[use[1] for use in usage]\n",
    "fileData['uses_normalized']=u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Plots of Each Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Par Plot for all Signals in DF, dynamic for different number of signals\n",
    "def drawSignalPlots(fileData, signals, start_date, end_date, filename, events, save):\n",
    "    print(fileData.date_clean.min(), fileData.date_clean.max())\n",
    "    signals = [var for var in signals if var not in ['fileName', 'date', 'date_clean']]\n",
    "\n",
    "    plt.figure(num=None, figsize=(16, 4*len(signals)), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    i = 1\n",
    "    for signal in signals:\n",
    "        plt.subplot(len(signals), 1, i)\n",
    "        plt.plot(fileData.date_clean, fileData[signal], 'o')\n",
    "        # [plt.axvline(event, color = 'red', lw=2) for event in d.Date]\n",
    "        [plt.axvline(e, color = 'red', lw=2) for e in events]\n",
    "        # plt.plot(fileData.date_clean, fileData.semanticDensity)\n",
    "        plt.ylabel(signal)\n",
    "        plt.xlabel(\"Date\")\n",
    "        if i == 1:\n",
    "            plt.title(group+' Text Analysis')\n",
    "        #plt.axhline(fileData.god.mean(), color = 'green')\n",
    "        plt.axhspan(fileData[signal].quantile(0.25), fileData[signal].quantile(0.75), \\\n",
    "            facecolor='yellow', alpha=0.5)\n",
    "        plt.xlim([start_date,end_date])\n",
    "        i += 1\n",
    "    if save:\n",
    "        plt.savefig('./protest_temporalAnalysis/'+filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Std parameters for each group defined at the top of the file\n",
    "drawSignalPlots(fileData,fileData.columns,plotstart,plotend,group+'_temporal_all.pdf',d.Date,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Std parameters for each group defined at the top of the file\n",
    "drawSignalPlots(fileData,['uses','uses_normalized'],plotstart,plotend,group+'_temporal_uses.pdf',d.Date,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Draw plot with all signals on one graph, standardize the scale of the different signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Par Plot for all Signals in DF\n",
    "def drawStdSignalPlots(fileData, signals, start_date, end_date, filename, events, save):\n",
    "    \n",
    "    signals = [var for var in signals if var not in ['fileName', 'date', 'date_clean']]\n",
    "\n",
    "    # Standardize the Signals\n",
    "    fd_normalized = fileData[['fileName','date_clean']]\n",
    "    for signal in signals:\n",
    "        fd_normalized[signal] = min_max_scaler.fit_transform(fileData[signal])  \n",
    "        \n",
    "    plt.figure(num=None, figsize=(16, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    i = 1\n",
    "    for signal in signals:\n",
    "        # plt.subplot(len(signals), 1, i)\n",
    "        plt.plot(fd_normalized.date_clean, fd_normalized[signal], '-', marker='o')\n",
    "        # [plt.axvline(event, color = 'red', lw=2) for event in d.Date]\n",
    "        [plt.axvline(e, color = 'red', lw=2) for e in events]\n",
    "        # plt.plot(fd_normalized.date_clean, fd_normalized.semanticDensity)\n",
    "        plt.ylabel('Normalized Signal')\n",
    "        plt.xlabel(\"Date\")\n",
    "        if i == 1:\n",
    "            plt.title(group+' Text Analysis')\n",
    "        #plt.axhline(fd_normalized.god.mean(), color = 'green')\n",
    "        # plt.axhspan(fd_normalized[signal].quantile(0.25), fd_normalized[signal].quantile(0.75), \\\n",
    "        #     facecolor='yellow', alpha=0.5)\n",
    "        plt.xlim([start_date,end_date])\n",
    "        i += 1\n",
    "        plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "    if save:\n",
    "        plt.savefig('./protest_temporalAnalysis/'+filename)\n",
    "    plt.show()\n",
    "    \n",
    "    # return fd_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drawStdSignalPlots(fileData,fileData.columns,plotstart,plotend,group+'_std_all.pdf',d.Date,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileData[['uses','uses_normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drawStdSignalPlots(fileData,['uses','uses_normalized'],plotstart,plotend,group+'_std_uses.pdf',d.Date,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drawStdSignalPlots(fileData,['semanticDensity_the','semanticDensity_adjadv'],plotstart,plotend,group+'_std_semDensity.pdf',d.Date,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting w/ 2 Y-Scales\n",
    "fig = plt.figure(num=None, figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(fileData.date_clean, fileData.uses, marker='o')\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel('semantic density')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(fileData.date_clean, fileData.uses_normalized, 'green', marker='o')\n",
    "ax2.set_ylabel('word count')\n",
    "\n",
    "plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [rel35]",
   "language": "python",
   "name": "Python [rel35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
